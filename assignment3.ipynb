{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cded95f0",
   "metadata": {},
   "source": [
    "Install all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dff6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langgraph pinecone-client langchain-pinecone google-cloud-aiplatform pandas pydantic --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250209d",
   "metadata": {},
   "source": [
    "Import all the dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f4a09",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "import pinecone\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46213720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "with open(\"self_critique_loop_dataset.json\", \"r\") as f:\n",
    "    kb_data = json.load(f)\n",
    "\n",
    "print(\"Loaded KB entries:\", len(kb_data))\n",
    "pd.DataFrame(kb_data).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings & Pinecone Indexing referred from Assignment3_pinecone_quickstart_guide.ipynb\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\", \"<YOUR_PINECONE_KEY>\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\", \"<YOUR_PINECONE_ENV>\")\n",
    "INDEX_NAME = \"assignment3-kb\"\n",
    "\n",
    "# Init Pinecone\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "\n",
    "# Create index if missing\n",
    "if INDEX_NAME not in pinecone.list_indexes():\n",
    "    pinecone.create_index(INDEX_NAME, dimension=768)\n",
    "\n",
    "# Embeddings\n",
    "embedding_model = VertexAIEmbeddings(model_name=\"gemini-embedding-001\")\n",
    "\n",
    "# Prepare texts & metadata\n",
    "texts, metadatas, ids = [], [], []\n",
    "for entry in kb_data:\n",
    "    text = entry.get(\"answer_snippet\") or entry.get(\"text\") or entry.get(\"question\",\"\")\n",
    "    doc_id = entry.get(\"doc_id\") or entry.get(\"id\") or f\"KB_{len(ids)+1}\"\n",
    "    meta = {\n",
    "        \"doc_id\": doc_id,\n",
    "        \"question\": entry.get(\"question\",\"\"),\n",
    "        \"source\": entry.get(\"source\",\"\"),\n",
    "        \"last_updated\": entry.get(\"last_updated\",\"\")\n",
    "    }\n",
    "    texts.append(text)\n",
    "    metadatas.append(meta)\n",
    "    ids.append(doc_id)\n",
    "\n",
    "# Vectorstore (LangChain-Pinecone wrapper from quickstart)\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=INDEX_NAME,\n",
    "    embedding=embedding_model,\n",
    "    namespace=None,\n",
    "    pinecone_api_key=PINECONE_API_KEY,\n",
    ")\n",
    "\n",
    "# Upsert KB\n",
    "vectorstore.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
    "print(f\"Upserted {len(ids)} docs into Pinecone index {INDEX_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdcf4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph Workflow\n",
    "\n",
    "llm = VertexAI(model=\"gemini-pro\", temperature=0)\n",
    "\n",
    "class RAGState(Dict[str, Any]):\n",
    "    question: str\n",
    "    retrieved_docs: list\n",
    "    answer: str\n",
    "    critique: str\n",
    "\n",
    "# Node 1: Retrieve\n",
    "def retrieve_kb(state: RAGState):\n",
    "    docs = vectorstore.similarity_search(state[\"question\"], k=5)\n",
    "    state[\"retrieved_docs\"] = [d.page_content for d in docs]\n",
    "    return state\n",
    "\n",
    "# Node 2: Generate\n",
    "def generate_answer(state: RAGState):\n",
    "    context = \"\\n\".join(state[\"retrieved_docs\"])\n",
    "    prompt = f\"\"\"\n",
    "    Question: {state['question']}\n",
    "    Context (KB): {context}\n",
    "    Provide an answer citing doc_ids as [KBxxx].\n",
    "    \"\"\"\n",
    "    state[\"answer\"] = llm(prompt)\n",
    "    return state\n",
    "\n",
    "# Node 3: Critique\n",
    "def critique_answer(state: RAGState):\n",
    "    prompt = f\"\"\"\n",
    "    Review this answer:\n",
    "    {state['answer']}\n",
    "    Decide if it's COMPLETE or needs refinement.\n",
    "    Respond with either:\n",
    "    COMPLETE\n",
    "    REFINE: <keywords>\n",
    "    \"\"\"\n",
    "    state[\"critique\"] = llm(prompt)\n",
    "    return state\n",
    "\n",
    "# Node 4: Refine\n",
    "def refine_answer(state: RAGState):\n",
    "    if state[\"critique\"].startswith(\"REFINE\"):\n",
    "        keywords = state[\"critique\"].replace(\"REFINE:\", \"\").strip()\n",
    "        docs = vectorstore.similarity_search(keywords, k=1)\n",
    "        if docs:\n",
    "            state[\"retrieved_docs\"].append(docs[0].page_content)\n",
    "        context = \"\\n\".join(state[\"retrieved_docs\"])\n",
    "        prompt = f\"\"\"\n",
    "        Question: {state['question']}\n",
    "        Context (KB): {context}\n",
    "        Provide a refined answer citing doc_ids as [KBxxx].\n",
    "        \"\"\"\n",
    "        state[\"answer\"] = llm(prompt)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LangGraph\n",
    "\n",
    "graph = StateGraph(RAGState)\n",
    "\n",
    "graph.add_node(\"retrieve_kb\", retrieve_kb)\n",
    "graph.add_node(\"generate_answer\", generate_answer)\n",
    "graph.add_node(\"critique_answer\", critique_answer)\n",
    "graph.add_node(\"refine_answer\", refine_answer)\n",
    "\n",
    "graph.set_entry_point(\"retrieve_kb\")\n",
    "graph.add_edge(\"retrieve_kb\", \"generate_answer\")\n",
    "graph.add_edge(\"generate_answer\", \"critique_answer\")\n",
    "\n",
    "def critique_condition(state: RAGState):\n",
    "    return \"refine_answer\" if state[\"critique\"].startswith(\"REFINE\") else END\n",
    "\n",
    "graph.add_conditional_edges(\"critique_answer\", critique_condition)\n",
    "graph.add_edge(\"refine_answer\", END)\n",
    "\n",
    "compiled_graph = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f430853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Queries\n",
    "\n",
    "test_queries = [\n",
    "    \"What are best practices for caching?\",\n",
    "    \"How should I set up CI/CD pipelines?\",\n",
    "    \"What are performance tuning tips?\",\n",
    "    \"How do I version my APIs?\",\n",
    "    \"What should I consider for error handling?\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for q in test_queries:\n",
    "    final_state = compiled_graph.invoke({\"question\": q})\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"answer\": final_state[\"answer\"],\n",
    "        \"critique\": final_state[\"critique\"]\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d314d130",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
